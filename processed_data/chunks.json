{
  "metadata": {
    "source_file": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
    "processed_at": "2025-12-12T13:35:40.382957",
    "chunk_config": {
      "chunk_size": 800,
      "chunk_overlap": 100
    },
    "total_chunks": 43
  },
  "chunks": [
    {
      "id": "chunk_0000",
      "content": "# Building effective agents  \nWe've worked with dozens of teams building LLM agents across industries. Consistently, the most successful implementations use simple, composable patterns rather than complex frameworks.  \nOver the past year, we've worked with dozens of teams building large language model (LLM) agents across industries. Consistently, the most successful implementations weren't using complex frameworks or specialized libraries. Instead, they were building with simple, composable patterns.  \nIn this post, we share what we've learned from working with our customers and building agents ourselves, and give practical advice for developers on building effective agents.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building effective agents"
        ],
        "section_level": 1,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "introduction"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0001",
      "content": "# What are agents?  \n\"Agent\" can be defined in several ways. Some customers define agents as fully autonomous systems that operate independently over extended periods, using various tools to accomplish complex tasks. Others use the term to describe more prescriptive implementations that follow predefined workflows. At Anthropic, we categorize all these variations as agentic systems, but draw an important architectural distinction between workflows and agents:  \n- Workflows are systems where LLMs and tools are orchestrated through predefined code paths.\n- Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "What are agents?"
        ],
        "section_level": 1,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "definition",
          "workflow",
          "agent",
          "tool",
          "anthropic"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0002",
      "content": "Below, we will explore both types of agentic systems in detail. In Appendix 1 (\"Agents in Practice\"), we describe two domains where customers have found particular value in using these kinds of systems.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "What are agents?"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "appendix",
          "agents in practice",
          "example"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0003",
      "content": "# When (and when not) to use agents  \nWhen building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. This might mean not building agentic systems at all. Agentic systems often trade latency and cost  \nfor better task performance, and you should consider when this tradeoff makes sense.  \nWhen more complexity is warranted, workflows offer predictability and consistency for well-defined tasks, whereas agents are the better option when flexibility and model-driven decision-making are needed at scale. For many applications, however, optimizing single LLM calls with retrieval and in-context examples is usually enough.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "When (and when not) to use agents"
        ],
        "section_level": 1,
        "content_type": "example",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "definition",
          "agent_vs_workflow",
          "tradeoffs"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0004",
      "content": "# When and how to use frameworks  \nThere are many frameworks that make agentic systems easier to implement, including:  \n- The Claude Agent SDK;\n- Strands Agents SDK by AWS;\n- Rivet, a drag and drop GUI LLM workflow builder; and\n- Vellum, another GUI tool for building and testing complex workflows.  \nThese frameworks make it easy to get started by simplifying standard low-level tasks like calling LLMs, defining and parsing tools, and chaining calls together. However, they often create extra layers of abstraction that can obscure the underlying prompts and responses, making them harder to debug. They can also make it tempting to add complexity when a simpler setup would suffice.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "When and how to use frameworks"
        ],
        "section_level": 1,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "definition",
          "agent_vs_workflow",
          "tradeoffs"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0005",
      "content": "We suggest that developers start by using LLM APIs directly: many patterns can be implemented in a few lines of code. If you do use a framework, ensure you understand the underlying code. Incorrect assumptions about what's under the hood are a common source of customer error.  \nSee our cookbook for some sample implementations.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "When and how to use frameworks"
        ],
        "section_level": 1,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "framework",
          "llm"
        ],
        "workflow_type": null
      }
    },
    {
      "id": "chunk_0006",
      "content": "# Building blocks, workflows, and agents  \nIn this section, we'll explore the common patterns for agentic systems we've seen in production. We'll start with our foundational building block—the augmented  \nLLM—and progressively increase complexity, from simple compositional workflows to autonomous agents.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents"
        ],
        "section_level": 1,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "overview"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0007",
      "content": "## Building block: The augmented LLM  \nThe basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. Our current models can actively use these capabilities—generating their own search queries, selecting appropriate tools, and determining what information to retain.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Building block: The augmented LLM"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "memory",
          "llm",
          "retrieval"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0008",
      "content": "### Diagram Reference\n![The augmented LLM](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/28413a2de7f9de8fde06c678d06a0511dfa1c2a503e6018e18cd289962ab789d.jpg)  \nWe recommend focusing on two key aspects of the implementation: tailoring these capabilities to your specific use case and ensuring they provide an easy, well-documented interface for your LLM. While there are many ways to implement these augmentations, one approach is through our recently released Model Context Protocol, which allows developers to integrate with a growing ecosystem of third-party tools with a simple client implementation.  \nFor the remainder of this post, we'll assume each LLM call has access to these augmented capabilities.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Building block: The augmented LLM",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "llm"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0009",
      "content": "## Workflow: Prompt chaining  \nPrompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. You can add programmatic checks (see \"gate\" in the diagram below) on any intermediate steps to ensure that the process is still on track.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Prompt chaining"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "llm",
          "prompt"
        ],
        "workflow_type": "prompt_chaining"
      }
    },
    {
      "id": "chunk_0010",
      "content": "### Diagram Reference\n![The prompt chaining workflow](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/f628472eb54fbc7d09ce47c7bbdaea4de0c486f5c2c7000a528549e402c7710c.jpg)  \nWhen to use this workflow: This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Prompt chaining",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "llm",
          "prompt"
        ],
        "workflow_type": "prompt_chaining"
      }
    },
    {
      "id": "chunk_0011",
      "content": "#### Examples where prompt chaining is useful:  \n- Generating Marketing copy, then translating it into a different language.\n- Writing an outline of a document, checking that the outline meets certain criteria, then writing the document based on the outline.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Prompt chaining",
          "Diagram Reference",
          "Examples where prompt chaining is useful:"
        ],
        "section_level": 4,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "prompt"
        ],
        "workflow_type": "prompt_chaining"
      }
    },
    {
      "id": "chunk_0012",
      "content": "## Workflow: Routing  \nRouting classifies an input and directs it to a specialized followup task. This workflow allows for separation of concerns, and building more specialized prompts. Without this workflow, optimizing for one kind of input can hurt performance on other inputs.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Routing"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "routing"
        ],
        "workflow_type": "routing"
      }
    },
    {
      "id": "chunk_0013",
      "content": "### Diagram Reference\n![Routig Lofic Workflow](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/8e0a20399bb739ad475750b6c4ef9924dbdc5ef577d9814d9a78dc293cec4aa4.jpg)  \nWhen to use this workflow: Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model/algorithm.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Routing",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "routing",
          "llm",
          "classification"
        ],
        "workflow_type": "routing"
      }
    },
    {
      "id": "chunk_0014",
      "content": "#### Examples where routing is useful:  \n- Directing different types of customer service queries (general questions, refund requests, technical support) into different downstream processes, prompts, and tools.\n- Routing easy/common questions to smaller, cost-efficient models like Claude Haiku 4.5 and hard/unusual questions to more capable models like Claude Sonnet 4.5 to optimize for best performance.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Routing",
          "Diagram Reference",
          "Examples where routing is useful:"
        ],
        "section_level": 4,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "claude",
          "workflow",
          "routing"
        ],
        "workflow_type": "routing"
      }
    },
    {
      "id": "chunk_0015",
      "content": "## Workflow: Parallelization  \nLLMs can sometimes work simultaneously on a task and have their outputs aggregated programmatically. This workflow, parallelization, manifests in two key variations:  \n- Sectioning: Breaking a task into independent subtasks run in parallel.\n- Voting: Running the same task multiple times to get diverse outputs.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Parallelization"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "parallelization"
        ],
        "workflow_type": "parallelization"
      }
    },
    {
      "id": "chunk_0016",
      "content": "### Diagram Reference\n![The parallelization workflow](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/bb7aaa2be05fc7c3adc13eb38f503ef461ac2249be7283a6e45228118a99b66d.jpg)  \nWhen to use this workflow: Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Parallelization",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "parallelization",
          "llm"
        ],
        "workflow_type": "parallelization"
      }
    },
    {
      "id": "chunk_0017",
      "content": "#### Examples where parallelization is useful:  \n##### Sectioning:  \n○ Implementing guardrails where one model instance processes user queries while another screens them for inappropriate content or requests. This tends to perform better than having the same LLM call handle both guardrails and the core response.\n○ Automating evals for evaluating LLM performance, where each LLM call evaluates a different aspect of the model's performance on a given prompt.  \n##### Voting:  \n- Reviewing a piece of code for vulnerabilities, where several different prompts review and flag the code if they find a problem.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Parallelization",
          "Diagram Reference",
          "Examples where parallelization is useful:"
        ],
        "section_level": 4,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "parallelization",
          "llm",
          "prompt"
        ],
        "workflow_type": "parallelization"
      }
    },
    {
      "id": "chunk_0018",
      "content": "- Evaluating whether a given piece of content is inappropriate, with multiple prompts evaluating different aspects or requiring different vote thresholds to balance false positives and negatives.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Parallelization",
          "Diagram Reference",
          "Examples where parallelization is useful:"
        ],
        "section_level": 4,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "parallelization"
        ],
        "workflow_type": "parallelization"
      }
    },
    {
      "id": "chunk_0019",
      "content": "## Workflow: Orchestrator-workers  \nIn the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Orchestrator-workers"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "llm",
          "orchestrator",
          "worker"
        ],
        "workflow_type": "orchestrator_workers"
      }
    },
    {
      "id": "chunk_0020",
      "content": "### Diagram Reference\n![The orchestrator-workers workflow](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/0b74247d8494fbaf2c85a9d91b6ccaefe6038028800a2174f2d40d0b4437c213.jpg)  \nWhen to use this workflow: This workflow is well-suited for complex tasks where you can't predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it's topographically similar, the key difference from parallelization is its flexibility—subtasks aren't pre-defined, but determined by the orchestrator based on the specific input.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Orchestrator-workers",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "parallelization",
          "orchestrator",
          "coding"
        ],
        "workflow_type": "parallelization"
      }
    },
    {
      "id": "chunk_0021",
      "content": "### Example where orchestrator-workers is useful:  \nCoding products that make complex changes to multiple files each time.\n- Search tasks that involve gathering and analyzing information from multiple sources for possible relevant information.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Orchestrator-workers",
          "Example where orchestrator-workers is useful:"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "orchestrator",
          "coding"
        ],
        "workflow_type": "orchestrator_workers"
      }
    },
    {
      "id": "chunk_0022",
      "content": "## Workflow: Evaluator-optimizer  \nIn the evaluator-optimizer workflow, one LLM call generates a response while another provides evaluation and feedback in a loop.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Evaluator-optimizer"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "evaluation",
          "llm",
          "feedback"
        ],
        "workflow_type": "evaluator_optimizer"
      }
    },
    {
      "id": "chunk_0023",
      "content": "### Diagram Reference\n![The evaluator-optimizer workflow](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/2e3c75b755f6f014e71138ca59a2af635389f6504667f142474636604dfee747.jpg)  \nWhen to use this workflow: This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Evaluator-optimizer",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "workflow",
          "evaluation",
          "llm",
          "feedback"
        ],
        "workflow_type": "evaluator_optimizer"
      }
    },
    {
      "id": "chunk_0024",
      "content": "### Examples where evaluator-optimizer is useful:  \n- Literary translation where there are nuances that the translator LLM might not capture initially, but where an evaluator LLM can provide useful critiques.\n- Complex search tasks that require multiple rounds of searching and analysis to gather comprehensive information, where the evaluator decides whether further searches are warranted.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Workflow: Evaluator-optimizer",
          "Examples where evaluator-optimizer is useful:"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "workflow",
          "llm"
        ],
        "workflow_type": "evaluator_optimizer"
      }
    },
    {
      "id": "chunk_0025",
      "content": "Agents are emerging in production as LLMs mature in key capabilities—understanding complex inputs, engaging in reasoning and planning, using tools reliably, and recovering from errors. Agents begin their work with either a command from, or interactive discussion with, the human user. Once the task is clear, agents plan and operate independently, potentially returning to the human for further information or judgement. During execution, it's crucial for the agents to gain \"ground truth\" from the environment at each step (such as tool call results or code execution) to assess its progress. Agents can then pause for human feedback at checkpoints or when encountering blockers",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "tool",
          "feedback"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0026",
      "content": ". Agents can then pause for human feedback at checkpoints or when encountering blockers. The task often terminates upon completion, but it's also common to include stopping conditions (such as a maximum number of iterations) to maintain control.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "feedback"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0027",
      "content": "Agents can handle sophisticated tasks, but their implementation is often straightforward. They are typically just LLMs using tools based on environmental feedback in a loop. It is therefore crucial to design toolsets and their documentation clearly and thoughtfully. We expand on best practices for tool development in (\"Prompt Engineering your Tools\").",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "feedback",
          "tool",
          "prompt"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0028",
      "content": "### Diagram Reference  \n![Autonomous agent](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/c0e39292c9108b1fc2440b289551b5fe5cab590ed581978405b148bbdab3e033.jpg)  \nWhen to use agents: Agents can be used for open-ended problems where it's difficult or impossible to predict the required number of steps, and where you can't hardcode a fixed path. The LLM will potentially operate for many turns, and you must have some level of trust in its decision-making. Agents' autonomy makes them ideal for scaling tasks in trusted environments.  \nThe autonomous nature of agents means higher costs, and the potential for compounding errors. We recommend extensive testing in sandboxed environments, along with the appropriate guardrails.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "agent",
          "llm"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0029",
      "content": "### Examples where agents are useful:  \nThe following examples are from our own implementations:  \n- A coding Agent to resolve SWE-bench tasks, which involve edits to many files based on a task description;\n- Our \"computer use\" reference implementation, where Claude uses a computer to accomplish tasks.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents",
          "Examples where agents are useful:"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "swe-bench",
          "agent",
          "coding",
          "claude"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0030",
      "content": "### Diagram Reference  \n![High-level flow of a coding agent](https://cdn-mineru.openxlab.org.cn/result/2025-12-12/d63ef72c-cfad-4191-849f-c7bc5c512e74/f8b98f261504853a0deb6f2d55079fe3cf8910241e92b82000c7b838f73f35ab.jpg)",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Agents",
          "Diagram Reference"
        ],
        "section_level": 3,
        "content_type": "workflow",
        "has_diagram": true,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "agent",
          "coding"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0031",
      "content": "## Combining and customizing these patterns  \nThese building blocks aren't prescriptive. They're common patterns that developers can shape and combine to fit different use cases. The key to success, as with any LLM features, is measuring performance and iterating on implementations. To repeat: you should consider adding complexity only when it demonstrably improves outcomes.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Combining and customizing these patterns"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "llm"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0032",
      "content": "## Summary  \nSuccess in the LLM space isn't about building the most sophisticated system. It's about building the right system for your needs. Start with simple prompts, optimize them with comprehensive evaluation, and add multi-step agentic systems only when simpler solutions fall short.  \nWhen implementing agents, we try to follow three core principles:  \n1. Maintain simplicity in your agent's design.\n2. Prioritize transparency by explicitly showing the agent's planning steps.\n3. Carefully craft your agent-computer interface (ACI) through thorough tool documentation and testing.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Summary"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "agent",
          "evaluation",
          "tool",
          "llm"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0033",
      "content": "Frameworks can help you get started quickly, but don't hesitate to reduce abstraction layers and build with basic components as you move to production. By following these principles, you can create agents that are not only powerful but also reliable, maintainable, and trusted by their users.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Building blocks, workflows, and agents",
          "Summary"
        ],
        "section_level": 2,
        "content_type": "workflow",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0034",
      "content": "# Acknowledgements  \nWritten by Erik Schluntz and Barry Zhang. This work draws upon our experiences building agents at Anthropic and the valuable insights shared by our customers, for which we're deeply grateful.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Acknowledgements"
        ],
        "section_level": 1,
        "content_type": "general",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "anthropic"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0035",
      "content": "# Appendix 1: Agents in practice  \nOur work with customers has revealed two particularly promising applications for AI agents that demonstrate the practical value of the patterns discussed above. Both applications illustrate how agents add the most value for tasks that require  \nboth conversation and action, have clear success criteria, enable feedback loops, and integrate meaningful human oversight.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 1: Agents in practice"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "feedback"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0036",
      "content": "# A. Customer support  \nCustomer support combines familiar chatbot interfaces with enhanced capabilities through tool integration. This is a natural fit for more open-ended agents because:  \n- Support interactions naturally follow a conversation flow while requiring access to external information and actions;\n- Tools can be integrated to pull customer data, order history, and knowledge base articles;\n- Actions such as issuing refunds or updating tickets can be handled programmatically; and\n- Success can be clearly measured through user-defined resolutions.  \nSeveral companies have demonstrated the viability of this approach through usage-based pricing models that charge only for successful resolutions, showing confidence in their agents' effectiveness.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "A. Customer support"
        ],
        "section_level": 1,
        "content_type": "example",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "customer support",
          "tool"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0037",
      "content": "# B. Coding agents  \nThe software development space has shown remarkable potential for LLM features, with capabilities evolving from code completion to autonomous problem-solving. Agents are particularly effective because:  \nCode solutions are verifiable through automated tests;\n- Agents can iterate on solutions using test results as feedback;\n- The problem space is well-defined and structured; and\nOutput quality can be measured objectively.  \nIn our own implementation, agents can now solve real GitHub issues in the SWE-bench Verified benchmark based on the pull request description alone. However, whereas automated testing helps verify functionality, human review remains crucial for ensuring solutions align with broader system requirements.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "B. Coding agents"
        ],
        "section_level": 1,
        "content_type": "general",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "swe-bench",
          "llm",
          "coding",
          "feedback"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0038",
      "content": "# Appendix 2: Prompt engineering your tools  \nNo matter which agentic system you're building, tools will likely be an important part of your agent. **Tools** enable Claude to interact with external services and APIs by specifying their exact structure and definition in our API. When Claude responds, it will include a **tool use block** in the API response if it plans to invoke a tool. Tool definitions and specifications should be given just as much prompt engineering attention as your overall prompts. In this brief appendix, we describe how to prompt engineer your tools.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 2: Prompt engineering your tools"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": false,
        "has_table": false,
        "topics": [
          "claude",
          "tool",
          "prompt",
          "api",
          "agent"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0039",
      "content": "There are often several ways to specify the same action. For instance, you can specify a file edit by writing a diff, or by rewriting the entire file. For structured output, you can return code inside markdown or inside JSON. In software engineering, differences like these are cosmetic and can be converted losslessly from one to the other. However, some formats are much more difficult for an LLM to write than others. Writing a diff requires knowing how many lines are changing in the chunk header before the new code is written. Writing code inside JSON (compared to markdown) requires extra escaping of newlines and quotes.  \nOur suggestions for deciding on tool formats are the following:  \n- Give the model enough tokens to \"think\" before it writes itself into a corner.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 2: Prompt engineering your tools"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "tool",
          "llm",
          "prompt"
        ],
        "workflow_type": null
      }
    },
    {
      "id": "chunk_0040",
      "content": "- Give the model enough tokens to \"think\" before it writes itself into a corner.\n- Keep the format close to what the model has seen naturally occurring in text on the internet.\n- Make sure there's no formatting \"overhead\" such as having to keep an accurate count of thousands of lines of code, or string-escaping any code it writes.  \nOne rule of thumb is to think about how much effort goes into human-computer interfaces (HCI), and plan to invest just as much effort in creating good agent-computer interfaces (ACI). Here are some thoughts on how to do so:",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 2: Prompt engineering your tools"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "agent",
          "prompt"
        ],
        "workflow_type": "agents"
      }
    },
    {
      "id": "chunk_0041",
      "content": "- Put yourself in the model's shoes. Is it obvious how to use this tool, based on the description and parameters, or would you need to think carefully about it? If so, then it's probably also true for the model. A good tool definition often includes example usage, edge cases, input format requirements, and clear boundaries from other tools.\n- How can you change parameter names or descriptions to make things more obvious? Think of this as writing a great docstring for a junior developer on your team. This is especially important when using many similar tools.\n- Test how the model uses your tools: Run many example inputs in our workbench to see what mistakes the model makes, and iterate.\n- Poka-yoke your tools. Change the arguments so that it is harder to make mistakes.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 2: Prompt engineering your tools"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "tool",
          "prompt"
        ],
        "workflow_type": null
      }
    },
    {
      "id": "chunk_0042",
      "content": "- Poka-yoke your tools. Change the arguments so that it is harder to make mistakes.  \nWhile building our agent for SWE-bench, we actually spent more time optimizing our tools than the overall prompt. For example, we found that the model would make mistakes with tools using relative filepaths after the agent had moved out of the root directory. To fix this, we changed the tool to always require absolute filepaths—and we found that the model used this method flawlessly.",
      "metadata": {
        "doc_title": "Building effective agents",
        "doc_source": "/Users/shilohjin/Desktop/Agent-Learn/halter-challenge-rag/raw_data/build_effective_ai_agents.md",
        "section_hierarchy": [
          "Appendix 2: Prompt engineering your tools"
        ],
        "section_level": 1,
        "content_type": "appendix",
        "has_diagram": false,
        "has_code": false,
        "has_list": true,
        "has_table": false,
        "topics": [
          "agent",
          "tool",
          "swe-bench",
          "prompt"
        ],
        "workflow_type": "agents"
      }
    }
  ]
}